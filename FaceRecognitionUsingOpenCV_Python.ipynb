{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE RECOGNITON USING PYTHON (OPENCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their are many cool thing that one can do with this great library (OpenCV). One of which is Face Recognition. This may not be something new but in this repository you will learn how to make a simplest live face recognizer.\n",
    "\n",
    "Face recognition is the task of identifying an already detected object as a known or unknown face. Often the problem of face recognition is confused with the problem of face detection. Face Recognition on the other hand is to decide if the \"face\" is someone known, or unknown, using for this purpose a database of faces in order to validate this input face.\n",
    "\n",
    "I have divided the task of real time facial recognition into the basic steps. The whole project is the combination of these three steps. They are:\n",
    "\t\t1. DATA SET GENRATION \n",
    "\t\t2. TRAINING THE MODEL \n",
    "\t\t3. LIVE FACE RECOGNITION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTING MODULES ##\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PATHS ##\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "path_of_trainingData = fileDir + r\"\\trainingData\"\n",
    "path_of_trainingfile = fileDir + r\"\\trainingdata.yml\"\n",
    "path_of_cascadeClassifier = fileDir + r\"\\haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT INITIALIZATION ##\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "face_detector = cv2.CascadeClassifier(path_of_cascadeClassifier)\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 : DataSet Generation\n",
    "\n",
    "The dataset for face recognition is made in following steps: \n",
    "* First of all, permission is granted to web cam and is initialized as **cap**, it starts to record video. Video is the frames or photos running very fast.\n",
    "* Now in every milisecond of time a frame is captured.\n",
    "* This frame is then converted into grayscale image as they are easy for comutation. These grayscale are then passed through haar cascade claassifier which is trained to detect faces in frames and provide its location.\n",
    "* After getting the location of face the faces are croped\n",
    "* These croped faces are then labeled for that particular person and stored in the folder for training data.\n",
    "        this is how the face dataset is made now this dataset is send for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATASETGENERATOR ##\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "def datasetGenerator():\n",
    "    id = input(\"enter student id:\")\n",
    "    s = 0\n",
    "    while(True): \n",
    "        r, img = cap.read()\n",
    "        gray = cv2.cvtColor(img,cv2.IMREAD_GRAYSCALE)#COLOR_BGR2GRAY)\n",
    "        face = face_detector.detectMultiScale(gray,1.3,5)\n",
    "        for(x,y,w,h) in face:\n",
    "            cv2.rectangle(gray,(x,y),(x+w,y+h),(0,255,0),5)\n",
    "            cv2.imwrite(str(path_of_trainingData)+\"/\"+str(id)+\".\"+str(s)+\".png\",gray[y:y+h,x:x+w])\n",
    "            cv2.imshow(\"face\",gray)\n",
    "            s=s+1\n",
    "        if cv2.waitKey(1) & 0xFF== ord(\"q\"):\n",
    "            break\n",
    "        if s>100:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 : TRAINING THE MODEL\n",
    "\n",
    "* Now in this step the face and there corresponding labels are accessed from training data folder and returned as a numpy array, this work is done by function “getImagesWithID”.\n",
    "* This function take the path of dataset folder and return the numpy array of image of face and corresponding IDs.\n",
    "* These are stored in variables and then passed to our recognizing model (LBPH face recognizing model).\n",
    "* Through train function model is trained and the training data is then stored in an YML file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TRAINING THE MODEL ##\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "def getImagesWithID(path):\n",
    "    imagePaths = [os.path.join(path_of_trainingData, f) for f in os.listdir(path_of_trainingData)]   \n",
    "    faces = []\n",
    "    IDs = []\n",
    "    for imagePath in imagePaths:      \n",
    "        facesImg = Image.open(imagePath).convert('L')\n",
    "        faceNP = np.array(facesImg, 'uint8')\n",
    "        ID= int(os.path.split(imagePath)[-1].split(\".\")[0])\n",
    "        faces.append(faceNP)\n",
    "        IDs.append(ID)\n",
    "        cv2.imshow(\"Adding faces for traning\",faceNP)\n",
    "        cv2.waitKey(10)\n",
    "    return np.array(IDs), faces\n",
    "\n",
    "def trainingTheModel():\n",
    "    print(\"TRAINING THE MODEL..................\")\n",
    "    Ids,faces = getImagesWithID(path_of_trainingData)\n",
    "    cv2.destroyAllWindows()\n",
    "    recognizer.train(faces,Ids)\n",
    "    recognizer.save(path_of_trainingfile)\n",
    "    print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(Ids))))\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 : LIVE FACE RECOGNITION\n",
    "\n",
    "* The data stored in training file is read by LBPH model.\n",
    "* Again, the web cam is started and start record frame.\n",
    "* Faces detected in these frame by haar cascade classifier.\n",
    "* Now these faces are passed to predict function in our model which return the ID and confidence by which it is predicting the given image which has been compared with the face trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIVE FACE RECOGNITION ##\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "def liveFaceRecognition():\n",
    "    recognizer.read(path_of_trainingfile)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    while True:\n",
    "        ret, im =cap.read()\n",
    "        gray=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "        faces=face_detector.detectMultiScale(gray, 1.3,5)\n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(im,(x,y),(x+w,y+h),(225,0,0),2)\n",
    "            Id, conf = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "            if(conf<50):\n",
    "                if(Id==26):\n",
    "                    Id=\"gaurav\"\n",
    "            cv2.putText(im,str(Id),(x,y-10),font,0.55,(0,255,0),1)\n",
    "        cv2.imshow('im',im) \n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CALLING ALL THREE FUNCTIONS ##\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "datasetGenerator()\n",
    "trainingTheModel()\n",
    "liveFaceRecognition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here is how the dataset has been generated by the above program:\n",
    "![](files\\Capture.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training of model on person's face dataset.\n",
    "![](files/Capture1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Live face recognition.\n",
    "![](files/Capture3.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
